{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5bf0f58",
   "metadata": {},
   "source": [
    "# ReadMe\n",
    "This notebook shows the process for loading and preprocessing data and training and optimizing a model. Written as a notebook instead of markdown for extra interactive fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41078f6b",
   "metadata": {},
   "source": [
    "## Preprocess, Train, and Optimize\n",
    "```data_utility.py``` and ```training_utility.py``` host the functions to open data, preprocess it, and train and optimize a model. Specifically, ```training_utility.py```'s ```main()``` function can easily do all of these together. Run the below code to try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f26d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import training_utility\n",
    "\n",
    "arch = training_utility.ModelArchitecture(steps_in=4, steps_out=1, resample_rate_min=60)\n",
    "opt_info = training_utility.OptimizationInfo(n_trials=1, n_splits=5, n_epochs=1, min_improvement=0, patience=5)\n",
    "\n",
    "training_utility.main('../ex_training_data', arch, opt_info, train_test_ratio=0.75, generate_new_data=True, export_folder='results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4859e626",
   "metadata": {},
   "source": [
    "Congrats, you just preprocess, trained, and optimized a (very poorly performing but quick to train) model!\n",
    "\n",
    "Let's break this down. ```main()``` has five parameters you can adjust:\n",
    "- ```dirname```: The directory of the training data. Results and preprocessed data will also be exported in this directory. See **\"Data Preprocessing\"** for more information on how this folder must be structured.\n",
    "- ```arch```: A ```ModelArchitecture``` object, which contains information about how the model is structured.\n",
    "- ```opt_info```: An ```OptimizationInfo``` object, which contains information about how you want to structure the optimization.\n",
    "- ```train_test_ratio``` (optional): A float between 0 and 1. What fraction of the dataset to use as training data. The exact amount may be adjusted slightly so the split does not split days into fractions. Defaults to 0.75.\n",
    "- ```generate_new_data``` (optional): If true, will open and preprocess data from scratch. Otherwise, will search for pickled preprocessed data in ```dirname```. Defaults to False.\n",
    "- ```export_folder``` (optional): Name of folder within ```dirname``` to store the model, optimization study, and data scalers. Defaults to an empty string (exporting to ```dirname```)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4c3e8b",
   "metadata": {},
   "source": [
    "Now, let's break down what goes into ```ModelArchitecture```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bfc203",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = training_utility.ModelArchitecture(steps_in=4, steps_out=1, resample_rate_min=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96909312",
   "metadata": {},
   "source": [
    "There are three parameters useful in this context:\n",
    "- ```steps_in```: The number of time steps inputed into the model to make predictions off of.\n",
    "- ```steps_out```: The length of the model's predictions in time steps.\n",
    "- ```resample_rate_min```: The length of each time step in minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4c3e8b",
   "metadata": {},
   "source": [
    "And finally, let's break down what goes into ```OptimizationInfo```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bfc203",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_info = training_utility.OptimizationInfo(n_trials=1, n_splits=5, n_epochs=1, min_improvement=0, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96909312",
   "metadata": {},
   "source": [
    "Here are the parameters:\n",
    "- ```n_trials```: How many trials to optimize the model.\n",
    "- ```n_splits``` (optional): How many splits to use in time series cross validation. Defaults to 5.\n",
    "- ```n_epochs``` (optional): How many epochs to train the model on. Defaults to 140.\n",
    "- ```batch_size``` (optional): Number of samples before updating model. If set to -1, will replace with the number of samples per day. Defaults to -1.\n",
    "- ```min_improvement``` (optional): Minimum improvement before early stopping. If < 0, does not implement early stopping. Defaults to 0.\n",
    "- ```patience``` (optional): Number of epochs to wait for improvement before early stopping. Defaults to 5.\n",
    "\n",
    "**Note on seasonal models:** If you would like to train a seasonal model, read the section \"Seasonal Models\" below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73b1ac1",
   "metadata": {},
   "source": [
    "And that's pretty much it! You can play with the variables to create a model of your liking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e239fba",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "You can also preprocess and pickle data for later use without training an entire model. All functions needed to load data and preprocess it are written and documented in ```data_utility.py```. You can look there for more specifics on what's going on, but the ```main()``` function covers everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6948dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_utility\n",
    "X, y = data_utility.main(steps_in=16, steps_out=4, resample_rate_min=15, dirname='../ex_training_data',\n",
    "    seasons=[[2,3,4],[5,6,7],[8,9,10],[11,12,1]], write_to_file=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69027a89",
   "metadata": {},
   "source": [
    "The ```main()``` function has a few key inputs:\n",
    "- ```steps_in``` The number of time steps inputed into the model to make predictions off of.\n",
    "- ```steps_out```: The length of the model's predictions in time steps.\n",
    "- ```resample_rate_min```: The length of each time step in minutes.\n",
    "- ```dirname```: The directory of the training data. Preprocessed data will be exported to a file in this directory if ```write_to_file``` is true..\n",
    "- ```seasons``` (optional): An array grouping each month into seasons. Providing this will train a seasonal model. See Seasonal Models section below for more information. Defaults to None.\n",
    "- ```write_to_file``` (optional): Whether or not to pickle the preprocessed data to file. Defaults to False.\n",
    "\n",
    "```main()``` also returns ```X``` and ```y```, which is the data fed into the model and the data compared against, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b0fb92",
   "metadata": {},
   "source": [
    "Note that the given directory must be structured as follows:\n",
    "- **Solar irradiance data** with suffix **.nc** in a folder called **sol_irr**\n",
    "- **Cloud coverage data** with suffix **.cdf** in a folder called **cloud_coverage**\n",
    "*You can change the names of these folders and suffixes of these files at the top of ```data_utility.py```*\n",
    "\n",
    "This code was created based on the ARMS [Radiative Flux Analysis](https://www.arm.gov/capabilities/vaps/radfluxanal) (solar irradiance) and [TSI Sky Cover](https://www.arm.gov/capabilities/instruments/tsi) (cloud coverage) data from the Southern Great Plains site. It is set to open data files using xarray, so any filetype supported by xarray should work fine. However, use of other datasets will require changing the input and output var names in ```data_utility.py```'s ```PreprocessingInstructions``` and may require additional rewriting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ef8b31",
   "metadata": {},
   "source": [
    "## Seasonal Models\n",
    "A **non-seasonal model** is one model for all times of the year.<br>\n",
    "A **seasonal model** is a model fine-tuned to different times of the year. Practically speaking, it is comprised of distinct models, each of which train on a specific subset of the data. Data can be split by months.\n",
    "\n",
    "```training_utility.py``` will load or open data and train the model on all the data given. This works well for non-seasonal models. However, if you would like to train a seasonal model, you will have to finaggle a little bit. You will have to load and preprocess the data, and then call ```training_utility.py```'s ```main()``` on each season's data, as done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b471c58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------paths to open determined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coder\\AppData\\Local\\Temp\\ipykernel_3452\\3229430983.py:24: UserWarning: Warning: Could not load data for ../ex_training_data\\[2, 3, 4], error message [WinError 3] The system cannot find the path specified: '../ex_training_data\\\\[2, 3, 4]'. May be that data does not have datafor this season, so no file to open.\n",
      "  warnings.warn(f\"Warning: Could not load data for {season_dirname}, error message {err}. May be that data does not have data\"\n",
      "\u001b[32m[I 2022-08-14 15:37:43,570]\u001b[0m A new study created in memory with name: no-name-475638a3-809d-4285-b915-7763fe9aad9b\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------sol irr data opened\n",
      "---------cloud coverage data opened\n",
      "---------data merged\n",
      "---------data preprocessed\n",
      "---------time series set up\n",
      "---------pickled to file, path: ../ex_training_data\\[5, 6, 7]\\14in.1out.60min.[5, 6, 7].X.pickle\n",
      "---------pickled to file, path: ../ex_training_data\\[5, 6, 7]\\14in.1out.60min.[5, 6, 7].y.pickle\n",
      "-----data loaded\n",
      "-----begin training\n",
      "-----epoch #1\n",
      "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_train_function.<locals>.train_function at 0x00000214628E0820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_train_function.<locals>.train_function at 0x00000214628E0820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 1.0321\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000214628E0670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000214628E0670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.4808\n",
      "1/1 [==============================] - 1s 880ms/step\n",
      "2/2 [==============================] - 3s 16ms/step - loss: 2.3091\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "2/2 [==============================] - 2s 16ms/step - loss: 3.5201\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "3/3 [==============================] - 2s 16ms/step - loss: 3.3552\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "loss=2.499190367294957, improvement, best_idx=0,curr_idx=1\n",
      "[inf, 2.499190367294957]\n",
      "-----training complete. evaluating model...\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-14 15:38:00,579]\u001b[0m Trial 0 finished with value: 0.6491945399220171 and parameters: {'n_neurons': 128, 'n_layers': 4, 'cell_type': 'SimpleRNN'}. Best is trial 0 with value: 0.6491945399220171.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----model evaluated\n",
      "-----training and optimization done\n",
      "INFO:tensorflow:Assets written to: ../ex_training_data\\[5, 6, 7]\\results\\best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../ex_training_data\\[5, 6, 7]\\results\\best_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----best model saved to ../ex_training_data\\[5, 6, 7]\\results\\best_model\n",
      "-----study saved to ../ex_training_data\\[5, 6, 7]\\results\\14in.1out.study.pickle\n",
      "-----scalers saved to ../ex_training_data\\[5, 6, 7]\\results\\scalers.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coder\\AppData\\Local\\Temp\\ipykernel_3452\\3229430983.py:24: UserWarning: Warning: Could not load data for ../ex_training_data\\[8, 9, 10], error message [WinError 3] The system cannot find the path specified: '../ex_training_data\\\\[8, 9, 10]'. May be that data does not have datafor this season, so no file to open.\n",
      "  warnings.warn(f\"Warning: Could not load data for {season_dirname}, error message {err}. May be that data does not have data\"\n",
      "C:\\Users\\coder\\AppData\\Local\\Temp\\ipykernel_3452\\3229430983.py:24: UserWarning: Warning: Could not load data for ../ex_training_data\\[11, 12, 1], error message [WinError 3] The system cannot find the path specified: '../ex_training_data\\\\[11, 12, 1]'. May be that data does not have datafor this season, so no file to open.\n",
      "  warnings.warn(f\"Warning: Could not load data for {season_dirname}, error message {err}. May be that data does not have data\"\n"
     ]
    }
   ],
   "source": [
    "import training_utility\n",
    "import data_utility\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# first preprocess and save the data (write_to_file must be True)\n",
    "# data will be saved at 'dirname/season/filename', e.g., 'dirname/[2,3,4]/16in.4out.15min.X.[5,6,7].pickle'\n",
    "steps_in, steps_out = 14, 1\n",
    "resample_rate_min=60\n",
    "dirname='../ex_training_data'\n",
    "seasons=[[2,3,4],[5,6,7],[8,9,10],[11,12,1]]\n",
    "data_utility.main(steps_in=steps_in, steps_out=steps_out, resample_rate_min=resample_rate_min, dirname=dirname, seasons=seasons,\n",
    "    write_to_file=True)\n",
    "\n",
    "# now iteratively call training_utility.main() for each season's data (generate_new_data=False)\n",
    "arch = training_utility.ModelArchitecture(steps_in=steps_in, steps_out=steps_out, resample_rate_min=resample_rate_min)\n",
    "opt_info = training_utility.OptimizationInfo(n_trials=1, n_splits=5, n_epochs=1, min_improvement=0, patience=5)\n",
    "\n",
    "for season in seasons:\n",
    "    season_dirname = os.path.join(dirname, str(season))\n",
    "    try:\n",
    "        training_utility.main(season_dirname, arch, opt_info, train_test_ratio=0.75, generate_new_data=False, export_folder='results')\n",
    "    except FileNotFoundError as err:\n",
    "        # in case there is no data for that season\n",
    "        warnings.warn(f\"Warning: Could not load data for {season_dirname}, error message {err}. May be that data does not have data\"\n",
    "            \"for this season, so no file to open.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1785dcf101801635e756bb912841babeca560cb71b91fc4ced8de7e694d77769"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
